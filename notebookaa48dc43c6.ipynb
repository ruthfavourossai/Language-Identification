{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","    South Africa is a Multi Lingual speaking country with 11 Official Languages. Most of its citizens are able to speak more than one of these Languages. This project would create a model that can take in a text data in any of the 11 South African languages, and predict what language it is.\n","    "]},{"cell_type":"markdown","metadata":{},"source":["The relevant libraries needed for this project would be imported"]},{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-12T15:38:36.085466Z","iopub.status.busy":"2022-12-12T15:38:36.084146Z","iopub.status.idle":"2022-12-12T15:38:36.106767Z","shell.execute_reply":"2022-12-12T15:38:36.105599Z","shell.execute_reply.started":"2022-12-12T15:38:36.085408Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/south-african-language-identification-hack-2022/sample_submission.csv\n","/kaggle/input/south-african-language-identification-hack-2022/test_set.csv\n","/kaggle/input/south-african-language-identification-hack-2022/train_set.csv\n"]}],"source":["# Importing relevant libraries\n","# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["Due to how large the data set is, this analysis was perform directly on Kaggle and the data from kaggle was used."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#loading the data\n","#train data\n","df_train = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2022/train_set.csv')\n","#test data\n","df_test = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2022/test_set.csv')\n"]},{"cell_type":"markdown","metadata":{},"source":["Lets take a look at the data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:12:47.985715Z","iopub.status.busy":"2022-12-12T14:12:47.985255Z","iopub.status.idle":"2022-12-12T14:12:48.006815Z","shell.execute_reply":"2022-12-12T14:12:48.005804Z","shell.execute_reply.started":"2022-12-12T14:12:47.985674Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lang_id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>xho</td>\n","      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>xho</td>\n","      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>eng</td>\n","      <td>the province of kwazulu-natal department of tr...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nso</td>\n","      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ven</td>\n","      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  lang_id                                               text\n","0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n","1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n","2     eng  the province of kwazulu-natal department of tr...\n","3     nso  o netefatša gore o ba file dilo ka moka tše le...\n","4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_train.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:13:21.469237Z","iopub.status.busy":"2022-12-12T14:13:21.468111Z","iopub.status.idle":"2022-12-12T14:13:21.479623Z","shell.execute_reply":"2022-12-12T14:13:21.478624Z","shell.execute_reply.started":"2022-12-12T14:13:21.469164Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Winste op buitelandse valuta.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index                                               text\n","0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n","1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n","2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n","3      4  Kube inja nelikati betingevakala kutsi titsini...\n","4      5                      Winste op buitelandse valuta."]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head()"]},{"cell_type":"markdown","metadata":{},"source":["The test data does not have the Lang_id column this is because we would use it to test our data directly on Kaggle"]},{"cell_type":"markdown","metadata":{},"source":["Before building the model, some preprocessing of the data needs to be done to get the data in the right shape.\n","**CountVectoriser** would be used to transform the text data into numeric figures, fit for analysis"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T15:39:02.944012Z","iopub.status.busy":"2022-12-12T15:39:02.943183Z","iopub.status.idle":"2022-12-12T15:39:09.042326Z","shell.execute_reply":"2022-12-12T15:39:09.040836Z","shell.execute_reply.started":"2022-12-12T15:39:02.943957Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["#data preprocessing\n","#vectorising the data with 70000 features\n","vect = CountVectorizer(lowercase=True,max_features=100000)\n","#fitting the vectoriser to the train data\n","X_train = vect.fit_transform(df_train['text']) #creating train features\n","X_train= pd.DataFrame(X_train.A, columns=vect.get_feature_names()) #convert to dataframe\n","y_train = df_train['lang_id'] # creating train labels"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:19:47.728559Z","iopub.status.busy":"2022-12-12T14:19:47.727785Z","iopub.status.idle":"2022-12-12T14:19:48.326450Z","shell.execute_reply":"2022-12-12T14:19:48.325276Z","shell.execute_reply.started":"2022-12-12T14:19:47.728512Z"},"trusted":true},"outputs":[],"source":["#transforming test data\n","X_test = vect.transform(df_test['text']) #creating test features\n","X_test = pd.DataFrame(X_test.A, columns=vect.get_feature_names()) #converting to DataFrame"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:20:03.327335Z","iopub.status.busy":"2022-12-12T14:20:03.326786Z","iopub.status.idle":"2022-12-12T14:20:03.358151Z","shell.execute_reply":"2022-12-12T14:20:03.356687Z","shell.execute_reply.started":"2022-12-12T14:20:03.327291Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aa</th>\n","      <th>aabameli</th>\n","      <th>aaent</th>\n","      <th>aak</th>\n","      <th>aan</th>\n","      <th>aanbeveel</th>\n","      <th>aanbeveling</th>\n","      <th>aanbevelings</th>\n","      <th>aanbevole</th>\n","      <th>aanbied</th>\n","      <th>...</th>\n","      <th>ṱuvhana</th>\n","      <th>ṱuwa</th>\n","      <th>ṱuwe</th>\n","      <th>ṱuwedza</th>\n","      <th>ṱuwedzi</th>\n","      <th>ṱuṱuwedza</th>\n","      <th>ṱuṱuwedzaho</th>\n","      <th>ṱuṱuwedze</th>\n","      <th>ṱuṱuwedzea</th>\n","      <th>ṱuṱuwedzwa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 100000 columns</p>\n","</div>"],"text/plain":["   aa  aabameli  aaent  aak  aan  aanbeveel  aanbeveling  aanbevelings  \\\n","0   0         0      0    0    0          0            0             0   \n","1   0         0      0    0    0          0            0             0   \n","2   0         0      0    0    0          0            0             0   \n","3   0         0      0    0    0          0            0             0   \n","4   0         0      0    0    0          0            0             0   \n","\n","   aanbevole  aanbied  ...  ṱuvhana  ṱuwa  ṱuwe  ṱuwedza  ṱuwedzi  ṱuṱuwedza  \\\n","0          0        0  ...        0     0     0        0        0          0   \n","1          0        0  ...        0     0     0        0        0          0   \n","2          0        0  ...        0     0     0        0        0          0   \n","3          0        0  ...        0     0     0        0        0          0   \n","4          0        0  ...        0     0     0        0        0          0   \n","\n","   ṱuṱuwedzaho  ṱuṱuwedze  ṱuṱuwedzea  ṱuṱuwedzwa  \n","0            0          0           0           0  \n","1            0          0           0           0  \n","2            0          0           0           0  \n","3            0          0           0           0  \n","4            0          0           0           0  \n","\n","[5 rows x 100000 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#checking the test feature\n","X_test.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:20:15.957150Z","iopub.status.busy":"2022-12-12T14:20:15.956736Z","iopub.status.idle":"2022-12-12T14:20:15.984414Z","shell.execute_reply":"2022-12-12T14:20:15.982869Z","shell.execute_reply.started":"2022-12-12T14:20:15.957097Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aa</th>\n","      <th>aabameli</th>\n","      <th>aaent</th>\n","      <th>aak</th>\n","      <th>aan</th>\n","      <th>aanbeveel</th>\n","      <th>aanbeveling</th>\n","      <th>aanbevelings</th>\n","      <th>aanbevole</th>\n","      <th>aanbied</th>\n","      <th>...</th>\n","      <th>ṱuvhana</th>\n","      <th>ṱuwa</th>\n","      <th>ṱuwe</th>\n","      <th>ṱuwedza</th>\n","      <th>ṱuwedzi</th>\n","      <th>ṱuṱuwedza</th>\n","      <th>ṱuṱuwedzaho</th>\n","      <th>ṱuṱuwedze</th>\n","      <th>ṱuṱuwedzea</th>\n","      <th>ṱuṱuwedzwa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 100000 columns</p>\n","</div>"],"text/plain":["   aa  aabameli  aaent  aak  aan  aanbeveel  aanbeveling  aanbevelings  \\\n","0   0         0      0    0    0          0            0             0   \n","1   0         0      0    0    0          0            0             0   \n","2   0         0      0    0    0          0            0             0   \n","3   0         0      0    0    0          0            0             0   \n","4   0         0      0    0    0          0            0             0   \n","\n","   aanbevole  aanbied  ...  ṱuvhana  ṱuwa  ṱuwe  ṱuwedza  ṱuwedzi  ṱuṱuwedza  \\\n","0          0        0  ...        0     0     0        0        0          0   \n","1          0        0  ...        0     0     0        0        0          0   \n","2          0        0  ...        0     0     0        0        0          0   \n","3          0        0  ...        0     0     0        0        0          0   \n","4          0        0  ...        0     0     0        0        0          0   \n","\n","   ṱuṱuwedzaho  ṱuṱuwedze  ṱuṱuwedzea  ṱuṱuwedzwa  \n","0            0          0           0           0  \n","1            0          0           0           0  \n","2            0          0           0           0  \n","3            0          0           0           0  \n","4            0          0           0           0  \n","\n","[5 rows x 100000 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#checking the train feature\n","X_train.head()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T15:24:13.593479Z","iopub.status.busy":"2022-12-12T15:24:13.593044Z","iopub.status.idle":"2022-12-12T15:24:20.270799Z","shell.execute_reply":"2022-12-12T15:24:20.269401Z","shell.execute_reply.started":"2022-12-12T15:24:13.593445Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 33000 entries, 0 to 32999\n","Columns: 100000 entries, aa to ṱuṱuwedzwa\n","dtypes: int64(100000)\n","memory usage: 24.6 GB\n"]}],"source":["X_train.info()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T15:24:58.654546Z","iopub.status.busy":"2022-12-12T15:24:58.654145Z","iopub.status.idle":"2022-12-12T15:25:04.237746Z","shell.execute_reply":"2022-12-12T15:25:04.236449Z","shell.execute_reply.started":"2022-12-12T15:24:58.654514Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5682 entries, 0 to 5681\n","Columns: 100000 entries, aa to ṱuṱuwedzwa\n","dtypes: int64(100000)\n","memory usage: 4.2 GB\n"]}],"source":["X_test.info()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T15:25:34.264294Z","iopub.status.busy":"2022-12-12T15:25:34.263816Z","iopub.status.idle":"2022-12-12T15:25:34.274959Z","shell.execute_reply":"2022-12-12T15:25:34.273730Z","shell.execute_reply.started":"2022-12-12T15:25:34.264254Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n","       'sot', 'afr'], dtype=object)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["#checking the amount of unique languages in our data\n","y_train.unique()"]},{"cell_type":"markdown","metadata":{},"source":["\n","In trying to predict and get the best model, the following models where used.\n","1. Logistic Classifier\n","2. Decision tree Classifier\n","3. Random Forest Classifier\n","4. Multinomial NaiveBase Classifier"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:24:30.266904Z","iopub.status.busy":"2022-12-12T14:24:30.266357Z","iopub.status.idle":"2022-12-12T14:24:30.272054Z","shell.execute_reply":"2022-12-12T14:24:30.270792Z","shell.execute_reply.started":"2022-12-12T14:24:30.266861Z"},"trusted":true},"outputs":[],"source":["lm = LogisticRegression() #creating the model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:24:32.501089Z","iopub.status.busy":"2022-12-12T14:24:32.500611Z","iopub.status.idle":"2022-12-12T15:00:15.884868Z","shell.execute_reply":"2022-12-12T15:00:15.883306Z","shell.execute_reply.started":"2022-12-12T14:24:32.501049Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"data":{"text/plain":["LogisticRegression()"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#fitting the data\n","lm.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T10:19:42.059506Z","iopub.status.busy":"2022-12-12T10:19:42.058703Z","iopub.status.idle":"2022-12-12T10:19:59.908611Z","shell.execute_reply":"2022-12-12T10:19:59.906718Z","shell.execute_reply.started":"2022-12-12T10:19:42.059463Z"},"trusted":true},"outputs":[],"source":["#predicting the training data\n","y_pred = lm.predict(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T10:28:19.172606Z","iopub.status.busy":"2022-12-12T10:28:19.172077Z","iopub.status.idle":"2022-12-12T10:28:21.674467Z","shell.execute_reply":"2022-12-12T10:28:21.672731Z","shell.execute_reply.started":"2022-12-12T10:28:19.172566Z"},"trusted":true},"outputs":[],"source":["#predicting the test data \n","y_pred_test = lm.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["To test the predictive ability of this model a submition file needs to be created to submit to kaggle."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T10:28:32.897126Z","iopub.status.busy":"2022-12-12T10:28:32.896726Z","iopub.status.idle":"2022-12-12T10:28:32.903854Z","shell.execute_reply":"2022-12-12T10:28:32.902479Z","shell.execute_reply.started":"2022-12-12T10:28:32.897093Z"},"trusted":true},"outputs":[],"source":["# Creating Submittion file\n","submission = pd.DataFrame(df_test['index']) #getting the index column\n","submission['lang_id'] = pd.DataFrame(y_pred_test) #joining the lang_id column\n","submission.to_csv('submission.csv', index=False) # saving the file as csv\n"]},{"cell_type":"markdown","metadata":{},"source":["**KnearestNeighbors**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T10:31:22.805009Z","iopub.status.busy":"2022-12-12T10:31:22.804169Z","iopub.status.idle":"2022-12-12T10:31:23.198751Z","shell.execute_reply":"2022-12-12T10:31:23.197481Z","shell.execute_reply.started":"2022-12-12T10:31:22.804963Z"},"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier() # creating the model\n","knn.fit(X_train, y_train) # fitting the data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T10:31:27.110955Z","iopub.status.busy":"2022-12-12T10:31:27.110512Z"},"trusted":true},"outputs":[],"source":["y_hat = knn.predict(X_test) #predicting test data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T07:10:59.809825Z","iopub.status.busy":"2022-12-12T07:10:59.809322Z","iopub.status.idle":"2022-12-12T07:10:59.817578Z","shell.execute_reply":"2022-12-12T07:10:59.816018Z","shell.execute_reply.started":"2022-12-12T07:10:59.809782Z"}},"outputs":[],"source":["# Creating Submittion file\n","submission = pd.DataFrame(df_test['index'])\n","submission['lang_id'] = pd.DataFrame(y_hat)\n","submission.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["**DecisionTreeClassifier**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T07:11:10.730919Z","iopub.status.busy":"2022-12-12T07:11:10.729869Z","iopub.status.idle":"2022-12-12T07:11:10.736443Z","shell.execute_reply":"2022-12-12T07:11:10.735257Z","shell.execute_reply.started":"2022-12-12T07:11:10.730879Z"}},"outputs":[],"source":["tree = DecisionTreeClassifier(max_depth=5) #creating the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T07:11:11.994694Z","iopub.status.busy":"2022-12-12T07:11:11.994308Z","iopub.status.idle":"2022-12-12T07:11:31.891398Z","shell.execute_reply":"2022-12-12T07:11:31.890501Z","shell.execute_reply.started":"2022-12-12T07:11:11.994664Z"},"trusted":true},"outputs":[],"source":["tree.fit(X_train,y_train) #fitting the train data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T07:11:31.893932Z","iopub.status.busy":"2022-12-12T07:11:31.893065Z","iopub.status.idle":"2022-12-12T07:11:32.834303Z","shell.execute_reply":"2022-12-12T07:11:32.833325Z","shell.execute_reply.started":"2022-12-12T07:11:31.893880Z"},"trusted":true},"outputs":[],"source":["tree.predict(X_train) #predicting the train data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T07:11:32.836385Z","iopub.status.busy":"2022-12-12T07:11:32.835398Z","iopub.status.idle":"2022-12-12T07:11:33.063348Z","shell.execute_reply":"2022-12-12T07:11:33.062136Z","shell.execute_reply.started":"2022-12-12T07:11:32.836347Z"},"trusted":true},"outputs":[],"source":["y_tree_pred = tree.predict(X_test) #predicting the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Creating submittion file\n","submission = pd.DataFrame(df_test['index'])\n","submission['lang_id'] = pd.DataFrame(y_hat)\n","submission.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["**RandomForestClassifier**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating the model\n","rfc = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:11:33.132659Z","iopub.status.idle":"2022-12-12T07:11:33.133075Z","shell.execute_reply":"2022-12-12T07:11:33.132904Z","shell.execute_reply.started":"2022-12-12T07:11:33.132885Z"},"trusted":true},"outputs":[],"source":["rfc.fit(X_train,y_train) # fitting the data\n","rfc.predict(X_train) # predicting the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:11:33.134398Z","iopub.status.idle":"2022-12-12T07:11:33.134798Z","shell.execute_reply":"2022-12-12T07:11:33.134620Z","shell.execute_reply.started":"2022-12-12T07:11:33.134602Z"},"trusted":true},"outputs":[],"source":["y_rfc_pred = rfc.predict(X_test) #predicting the test data"]},{"cell_type":"markdown","metadata":{},"source":["**NaiveBayes(Multinomial)**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T15:39:23.283078Z","iopub.status.busy":"2022-12-12T15:39:23.282677Z","iopub.status.idle":"2022-12-12T15:39:23.288621Z","shell.execute_reply":"2022-12-12T15:39:23.287739Z","shell.execute_reply.started":"2022-12-12T15:39:23.283047Z"},"trusted":true},"outputs":[],"source":["mn =MultinomialNB() #Creating the data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T15:39:29.194053Z","iopub.status.busy":"2022-12-12T15:39:29.192841Z"},"trusted":true},"outputs":[],"source":["mn.fit(X_train, y_train) #fitting the data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T11:13:23.531643Z","iopub.status.busy":"2022-12-12T11:13:23.531102Z","iopub.status.idle":"2022-12-12T11:14:04.911641Z","shell.execute_reply":"2022-12-12T11:14:04.910253Z","shell.execute_reply.started":"2022-12-12T11:13:23.531602Z"},"trusted":true},"outputs":[],"source":["mn.predict(X_train) #predicting the train data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T11:15:06.112967Z","iopub.status.busy":"2022-12-12T11:15:06.112498Z","iopub.status.idle":"2022-12-12T11:15:11.610733Z","shell.execute_reply":"2022-12-12T11:15:11.608970Z","shell.execute_reply.started":"2022-12-12T11:15:06.112931Z"},"trusted":true},"outputs":[],"source":["mn_y_pred = mn.predict(X_test) #predicting the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T11:17:20.803159Z","iopub.status.busy":"2022-12-12T11:17:20.802664Z","iopub.status.idle":"2022-12-12T11:17:20.821815Z","shell.execute_reply":"2022-12-12T11:17:20.820544Z","shell.execute_reply.started":"2022-12-12T11:17:20.803116Z"},"trusted":true},"outputs":[],"source":["#Creating submittion file\n","submission = pd.DataFrame(df_test['index'])\n","submission['lang_id'] = pd.DataFrame(mn_y_pred )\n","submission.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Each of the models created above and their predictions were tested on kaggle using the F1 score to get the best performing model.\n","The best model with the highest F1 score was the NaiveBayes(multinomial) model qith a score of **0.9604**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
